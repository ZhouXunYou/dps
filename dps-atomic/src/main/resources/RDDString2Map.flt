package ${packagePath}

import dps.atomic.impl.AbstractAction
import dps.atomic.define.{AtomOperationDefine, AtomOperationParamDefine}
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.SparkSession

import scala.collection.mutable.Map

class ${className}(override val sparkSession: SparkSession,override val inputVariableKey: String, override val outputVariableKey: String, override val variables: Map[String, Any]) extends dps.atomic.impl.AbstractAction(sparkSession,inputVariableKey, outputVariableKey, variables) with Serializable {
  def doIt(params: Map[String, String]): Any = {
    val rdd = this.pendingData.asInstanceOf[RDD[String]]
    val result = rdd.map(line => {
      processStringLine(line)
    })
    this.variables.put(outputVariableKey, result);
  }
  /**
   * @param line: 入参为 Rdd 的每一行数据，类型为 String
   * @return 将字符串变形后的 Map 对象
   */
  private def processStringLine(line: String): Map[String, Any] = {
    ${sourceCode}
  }
}