package ${packagePath}
import org.apache.spark.SparkContext
import scala.collection.mutable.Map
import org.apache.spark.sql.RowFactory
import org.apache.spark.sql.Row
import org.apache.spark.sql.types.StructField
import org.apache.spark.sql.types.DataTypes
import org.apache.spark.sql.types.StructType
import org.apache.spark.sql.SQLContext
import org.apache.spark.rdd.RDD
import dps.atomic.define.AtomOperationDefine
import dps.atomic.define.AtomOperationParamDefine
import dps.atomic.impl.AbstractAction

class ${className}(override val sparkContext:SparkContext,override val inputVariableKey: String, override val outputVariableKey: String, override val variables: Map[String, Any]) extends AbstractAction(sparkContext,inputVariableKey, outputVariableKey, variables) with Serializable {
  def doIt(params: Map[String, String]): Any = {
    val viewName = params.get("viewName").get
    val rdd = this.pendingData.asInstanceOf[RDD[Map[String,Any]]]
    val result = rdd.map(map => {
      buildRow(map)
    })
    var schema = StructType(specifyTableFields())
    val dataframe = new SQLContext(sparkContext).createDataFrame(result, schema)
    dataframe.createOrReplaceTempView(viewName)
    this.variables.put(outputVariableKey, dataframe);
  }
  
  private def specifyTableFields(): List[StructField] = {
    ${buildTableFieldCode}
  }
  
  private def buildRow(map: Map[String,Any]): Row = {
    ${buildTableRowCode}
  }
}