package ${packagePath}

import dps.atomic.impl.AbstractAction
import dps.atomic.define.{AtomOperationDefine, AtomOperationParamDefine}
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.SparkSession

import scala.collection.mutable.Map

class ${className} (override val sparkSession: SparkSession, override val inputVariableKey: String, override val outputVariableKey: String, override val variables: Map[String, Any]) extends AbstractAction(sparkSession, inputVariableKey, outputVariableKey, variables) with Serializable {
  def doIt(params: Map[String, String]): Any = {
    val leftRDD = params.get("leftVariableKey").get.asInstanceOf[RDD[Tuple2[String,String]]]
    val rightRDD = params.get("rightVariableKey").get.asInstanceOf[RDD[Tuple2[String,String]]]
    //e.g: left = (a:b,c,d),right = (a:e,f,g),result = (a:b,c,d,e,f,g)
    leftRDD.join(rightRDD)
  }
}