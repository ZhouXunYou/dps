package ${packagePath}

import dps.atomic.impl.AbstractAction
import dps.atomic.define.{AtomOperationDefine, AtomOperationParamDefine}
import org.apache.spark.sql.SparkSession

import scala.collection.mutable.Map
import org.apache.spark.SparkConf
import java.sql.DriverManager
import java.sql.Connection
import java.util.Properties
import org.apache.spark.sql.Dataset
import java.sql.Timestamp
import org.apache.spark.sql.Row

class ${className}(override val sparkSession: SparkSession, override val sparkConf:SparkConf,override val inputVariableKey: String, override val outputVariableKey: String, override val variables: Map[String, Any]) extends AbstractAction(sparkSession, sparkConf,inputVariableKey, outputVariableKey, variables) with Serializable {
  
  def doIt(params: Map[String, String]): Any = {
    val dataset = this.pendingData.asInstanceOf[Dataset[Row]]
    
    val props = new Properties
    props.put("user", params.get("user").get)
    props.put("password", params.get("password").get)
    val conn: Connection = DriverManager.getConnection(params.get("url").get, props)
    try {
      dataset.foreach(row => {

        val sql = s"""${JDBCStatement}"""
        conn.createStatement().executeUpdate(sql)
      })
    } catch {
      case e: Exception => println(e.printStackTrace())
    } finally {
      conn.close()
    }
  }
}