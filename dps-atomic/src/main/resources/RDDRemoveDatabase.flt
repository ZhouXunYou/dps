package ${packagePath}

import java.sql.Connection
import java.sql.DriverManager
import java.sql.PreparedStatement
import java.util.Properties

import scala.collection.mutable.Map

import org.apache.spark.SparkConf
import org.apache.spark.sql.Dataset
import org.apache.spark.sql.Row
import org.apache.spark.sql.SparkSession

import dps.atomic.define.AtomOperationDefine
import dps.atomic.define.AtomOperationParamDefine

class ${className}(override val sparkSession: SparkSession, override val sparkConf:SparkConf,override val inputVariableKey: String, override val outputVariableKey: String, override val variables: Map[String, Any]) extends AbstractAction(sparkSession, sparkConf,inputVariableKey, outputVariableKey, variables) with Serializable {
  def doIt(params: Map[String, String]): Any = {
    val dataset = this.pendingData.asInstanceOf[Dataset[Row]]
    if (dataset != null && dataset.isEmpty) {
      println("+------------------------------+")
      println("无数据,跳过移除操作")
      println("+------------------------------+")
    } else {
      val props = new Properties
      props.put("user", params.get("user").get)
      props.put("password", params.get("password").get)
      val conn: Connection = DriverManager.getConnection(params.get("url").get, props)
      conn.setAutoCommit(false)
      try {
        val sql = s""""delete from ${params.get("table").get} where ${params.getOrElse("field", "id")} = ?1""".stripMargin
        val stmt: PreparedStatement = conn.prepareStatement(sql)

        dataset.foreach(f => {
          stmt.setString(1, f.getAs("\"".+(params.getOrElse("field", "id")).+("\"")).asInstanceOf[String])
        })

        stmt.executeBatch()
        conn.commit()
      } catch {
        case e: Exception => println(e.printStackTrace())
      } finally {
        conn.close()
      }
    }
  }
}